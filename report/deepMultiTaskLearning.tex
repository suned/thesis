\section{Deep Multi-Task Learning}
\label{deep_multi-task_learning}
Neural networks have the advantage of being easy to adapt from single-task learning to multi-task learning by sharing the weights of early layers of a neural network architecture between learning tasks and learning them simultaneously \citep{caruana1997}. As an example, consider figure \ref{no_weight_sharing} and \ref{weight_sharing}.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->, >=stealth, swap]
			\node [neuron] (x11) at (0,0) {};
			\node [neuron] (x12) at (1,0) {};
			\node [neuron] (x13) at (2,0) {};
			\node [neuron] (x14) at (3,0) {};
			\node [neuron] (x15) at (4,0) {};
			\node [neuron] (sigma11) at (1,1.5) {};
			\node [neuron] (sigma12) at (2,1.5) {};
			\node [neuron] (sigma13) at (3,1.5) {};
			\node [neuron] (out1) at (2,3) {};	
			\node [] (label1) at (2,4) {Task 1};	
			\draw (x11) edge (sigma11);
			\draw (x12) edge (sigma11);
			\draw (x13) edge (sigma11);
			
			\draw (x12) edge (sigma12);
			\draw (x13) edge (sigma12);
			\draw (x14) edge (sigma12);
			
			\draw (x13) edge (sigma13);
			\draw (x14) edge (sigma13);
			\draw (x15) edge (sigma13);
			
			\draw (sigma11) edge (out1);
			\draw (sigma12) edge (out1);
			\draw (sigma13) edge (out1);
			
			\node [neuron] (x21) at (6,0) {};
			\node [neuron] (x22) at (7,0) {};
			\node [neuron] (x23) at (8,0) {};
			\node [neuron] (x24) at (9,0) {};
			\node [neuron] (x25) at (10,0) {};
			\node [neuron] (sigma21) at (7,1.5) {};
			\node [neuron] (sigma22) at (8,1.5) {};
			\node [neuron] (sigma23) at (9,1.5) {};
			\node [neuron] (out2) at (8,3) {};	
			\node [] (label2) at (8,4) {Task 2};	
			\draw (x21) edge (sigma21);
			\draw (x22) edge (sigma21);
			\draw (x23) edge (sigma21);
			
			\draw (x22) edge (sigma22);
			\draw (x23) edge (sigma22);
			\draw (x24) edge (sigma22);
			
			\draw (x23) edge (sigma23);
			\draw (x24) edge (sigma23);
			\draw (x25) edge (sigma23);
			
			\draw (sigma21) edge (out2);
			\draw (sigma22) edge (out2);
			\draw (sigma23) edge (out2);
	\end{tikzpicture}
	\caption{Visual representation of single-task learning with neural networks. A set of neural network weights are learnt separately for Task 1 and Task 2.}
	\label{no_weight_sharing}
\end{figure}

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->, >=stealth, swap]
			\node [neuron] (x1) at (0,0) {};
			\node [neuron] (x2) at (1,0) {};
			\node [neuron] (x3) at (2,0) {};
			\node [neuron] (x4) at (3,0) {};
			\node [neuron] (x5) at (4,0) {};
			\node [neuron] (sigma1) at (1,1.5) {};
			\node [neuron] (sigma2) at (2,1.5) {};
			\node [neuron] (sigma3) at (3,1.5) {};
			\node [neuron] (out1) at (1.3,3) {};	
			\node [neuron] (out2) at (2.7,3) {};
			\node [] (label1) at (1.3,4) {Task 1};
			\node [] (label2) at (2.7,4) {Task 2};
			\draw (x1) edge (sigma1);
			\draw (x2) edge (sigma1);
			\draw (x3) edge (sigma1);
			
			\draw (x2) edge (sigma2);
			\draw (x3) edge (sigma2);
			\draw (x4) edge (sigma2);
			
			\draw (x3) edge (sigma3);
			\draw (x4) edge (sigma3);
			\draw (x5) edge (sigma3);
			
			\draw (sigma1) edge (out1);
			\draw (sigma2) edge (out1);
			\draw (sigma3) edge (out1);
			
			\draw (sigma1) edge (out2);
			\draw (sigma2) edge (out2);
			\draw (sigma3) edge (out2);
	\end{tikzpicture}
	\caption{Visual representation multi-task learning with neural networks. The weights of the first layer is shared between the two tasks.}
	\label{weight_sharing}
\end{figure}
\noindent
Multi-task learning techniques that are based on sharing neural network weights between tasks are collectively known as \textbf{deep multi-task learning} techniques. Deep multi-task learning is closely associated with the idea of representation learning presented in section \ref{representation_learning} and the more general framework of bias learning presented in section \ref{bias_learning}. The network represents a shared representation $f(\vector{x})$ represented by $S$ shared layers, often the first layers, and hypotheses $h_1 = (g_1 \circ f)(\vector{x})$ to $h_M = (g_M \circ f)(\vector{x})$ for each learning task, where $g_m$ is $L - S$ neural network layers specific to each task.
\\\\
The exact circumstances under which deep multi-task learning leads to lower overall generalisation error compared to deep single-task learning are not yet theoretically well understood. \citet{caruana1997} lists 3 conjectures on how multi-task learning can reduce generalisation error:
\begin{description}
	\item [Statistical Data Amplification] The effective number of training examples available to a deep multi-task learning system is increased due to the examples in the auxiliary data. The extensions to the Vapnik-Chervonenkis bound seen in the preceding sections gives us confidence that this reduces the risk that generalisation error is far away from training error.
	\item [Eavesdropping] If a hidden layer feature is useful to both Task 1 and Task 2, but much easier to learn when learning Task 2, sharing the hidden layer between the two tasks is likely to reduce generalisation error for Task 1.
	\item [Representation Bias] If Task 1 and Task 2 share a common minimum in weight-space, learning the tasks with weight sharing biases the learning system to choose the shared minimum. This is effectively a form of regularisation that forces the learning system to search for a good hypothesis in a hypothesis space that is restricted to hypotheses that are useful for more than one task.
	\item \end{description}

\citet{galanti2016} develops a framework based on the bias learning framework by \citet{baxter2000} that may be used to gain some intuition on when and how deep multi-task learning is beneficial.