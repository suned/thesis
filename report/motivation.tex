\section{Motivation}
The volume of digital text that exists in the world is rapidly increasing: The number of active science journals is growing with an annual rate of approximately 2.5\%. The total number of published articles in these journals grew from 1.8 in 2009 to 2.5 million in 2015 \citep{ware2009, ware2015}. Similar staggering growth rates can be cited for content produced by online newspapers, social media and digital documents generated by businesses \citep{perrin2015, mitchell2015}.
\\\\
Finding the right information at the right time in the face of this data volume is challenging. A significant reason is that information contained in digital text is in the form of natural language which is often cited as being \textbf{unstructured} (despite the fact that natural language is actually highly structured). Unstructured data can be understood as essentially the opposite of the kind of data we find in relational databases where every data item is associated with metadata such as column names and column types. This metadata makes the structured data easy to search and analyze with computers. In contrast, unstructured data such as text, images, sound and video is not.
\\\\
This problem has driven the development of so called \textbf{information extraction} techniques. The goal of these is to assign metadata to unstructured data, thereby giving some structure to it. This is an ambitious goal since in many cases it involves developing computer systems that perform tasks such as recognizing objects in images, converting speech to text or building data structures that capture the semantics of natural language, tasks we don't fully understand how humans are able to perform.
\\\\
\textbf{Relation extraction} is an information extraction task the goal of which is to automatically identify a fixed set of semantic relationships of interest such as \textit{Father-Son(Luke Skywalker, Darth Vader)} when they occur in natural language. Identifying these relations can significantly improve the quality of applications such as information retrieval or question answering systems \citep{jurafsky09}.

Like most other natural language processing problems, relation extraction is extremely challenging because of the high degree of variation and ambiguity of natural language. Relation extraction systems are therefore usually composed of composed of sub-systems that each solve a sub-problem of relation extraction. Specifically, most relation extraction systems proceed by first identifying the potential arguments such as \textit{Luke Skywalker} and \textit{Darth Vader} in our example for any relation of interest. The system then detects whether or not a relation does in fact exist between them, and finally classifies the relation if it exists.
\\\\
\textbf{Supervised machine learning} in general, and \textbf{deep learning} in particular, are very successful techniques for solving information extraction problems. These approaches are based on the idea of supplying examples of inputs such as text and corresponding correct outputs, so called labels, that we would like the system to reproduce given the input. The goal is to teach the system to give approximately correct output for new inputs that it hasn't seen before.
\\\\
The conditions under which supervised machine learning systems can be expected to give approximately correct answers are fairly well understood. Theoretical analysis shows that the number of training examples provided for the learning system is one of the main ingredients in this guarantee. Producing these examples can be costly however: It often requires a human annotator with specialized skills to provide the correct labels. This means there is significant motivation for reusing labeled training data to reduce the need to create large new collections of data for each new supervised machine learning problem.
\\\\
\textbf{Multi-task learning} is a technique for reusing labeled data \citep{caruana1997}. In essence, it relies on the idea that it may be easier to learn related tasks simultaneously than in isolation, or in other words, that a learning system that learns from previously annotated data may require fewer examples for learning a new task, thereby reducing the cost of data annotation.