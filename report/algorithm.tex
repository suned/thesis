\section{Algorithm}

Our main goal is to investigate the sample complexity dynamics of learning a relation classification task in a multi-task learning setting. To this end, we compare the generalisation error of a deep learning model trained only on SemEval 2010 Task 8, the target task, with the generalisation error of a deep learning model trained jointly on the SemEval data and one of the auxiliary tasks described in \ref{auxiliary_tasks}.
\\\\
We proceed as follows: We vary the amount of data from the target task and auxiliary task in turn by a set of fractions. For every combination of fractional target and auxiliary data, we perform 5-fold cross validation on the target data to yield 5 macro-F1 scores. We use the training data from the 4 training folds of target data and the auxiliary data to train the architecture described in \ref{network_architecture}. This is done by uniformly selecting one of the two tasks, sampling a mini-batch of the fractional training data from that task, and performing one gradient descent update with respect to cross-entropy error using the Adam algorithm described in section \ref{adam}. 
\\\\
This process is iterated until an early stopping criterion on the target training data is met. Specifically, $1/10$ of target training data is set aside for early stopping validation. When the cross-entropy error on the early stopping dataset has not improved for 200 iterations of mini-batch gradient descent, training is halted, and the model weights are reset to their best recorded value.

When the patience is exceeded we record the cross-validation macro-F1 on the target task test fold using the best recorded weights. Since neural network training is a random search procedure with respect to weight initialization and mini-batch sampling, we run this experiment for each combination of target and auxiliary fractional data 5 times, yielding a total of 25 random cross-validation splits for each combination. We have provided the algorithm used in our experiments as pseudocode in algorithm \ref{experiment_pseudocode}.
\begin{algorithm}
\begin{algorithmic}
	\Require $miniBatchSize$: an integer giving the mini-batch size
	\Require $targetData = \{(\vector{x}_{t1},\vector{y}_{t1}),\dots,(\vector{x}_{tN},\vector{y}_{tN})\}$
	\Require $auxiliaryData = \{(\vector{x}_{a1},\vector{y}_{a1}),\dots,(\vector{x}_{aN},\vector{y}_{aN})\}$
	\Require $sample(data, fraction)$: A routine that can sample $|set| \cdot fraction$ samples from the set $data$ uniformly.
	\Require $crossValidation(data)$: A routine that returns a set of cross-validation folds over the set $data$.
	\Require $initializeWeights()$: A routine that can initialize a neural network weight vector.
	\Require $gradientDescent(data, w)$: A routine that performs gradient descent on the neural network weights $w$.
	\Require $macroF1(w, data)$: A routine that computes the macro F1 score on $data$ using neural network weights $w$.
	\Require $report(score, targetFraction, auxiliaryFraction)$: A reporting routine.
	\State $fractions \gets \{\frac{0}{5}, \frac{1}{5}, \frac{2}{5}, \frac{3}{5}, \frac{4}{5}, 1\}$
	\For{$iteration \in \{1,\dots,5\}$}
		\For{$targetFraction \in fractions$}
			\For{$auxiliaryFraction \in fractions$}
				\State $targetFractionalData \gets sample(targetData, targetFraction)$
				\State $auxiliaryFractionalData \gets sample(auxiliaryData, auxiliaryFraction)$
				\State $earlyStoppingData \gets sample(targetFractionalData, \frac{1}{10})$
				\State $targetTrainData = targetFractionalData \setminus earlyStoppingData$
				\For{$trainFold, testFold \in crossValidation(targetTrainData)$}
					\State $\vector{w} \gets initializeWeights()$
					\While{\textit{patience not exceeded}}
						\State $task \gets sample(\{trainFold, auxiliaryFractionalData\}, \frac{1}{2})$
						\State $miniBatch \gets sample(task, \frac{|task|}{miniBatchSize})$
						\State $\vector{w} \gets gradientDescent(miniBatch, \vector{w})$
					\EndWhile
					\State $score = macroF1(\vector{w}, testFold)$
					\State $report(score, targetFraction, auxiliaryFraction)$
				\EndFor
			\EndFor
		\EndFor
	\EndFor
\end{algorithmic}
\caption{Pseudocode for our deep multi-task learning experiment.}\label{experiment_pseudocode}
\end{algorithm}
